---
layout: post
title: Reflections on Communicating the Purpose of Models and Data Infrastructure to Stakeholders
date: 2025-04-05
author: Adish
tags: [stakeholder engagement, model communication, epidemiology]
---

Last month, our team had the opportunity to present the **Livestock Disease Modelling in India** initiative at a Gates Foundation event in Delhi. This was no ordinary stakeholder meeting—it brought together policymakers, researchers, and Gates leadership including Bill Gates. The challenge was to communicate the purpose of our work—spanning data mechanisms, model development, and institutional capacity building.

This initiative sits at the intersection of **disease informatics**, **epidemiological modelling**, and **systems strengthening**, anchored in a vision for integrated, scalable, and evidence-driven livestock disease management in India. It supports India’s **National Digital Livestock Mission (NDLM)** and complements strategic investments like the **National Animal Disease Information & Control Centre (NADICC)** at ICAR-NIVEDI.

At the heart of our presentation was a simple but powerful shift: from talking about what the model does to highlighting *why it exists* and *who it serves*. We focused on what real-world decisions these models enable, across what timescales, and how they fit into the evolving data infrastructure for animal health.

---

### Communicating in a Multistakeholder Room

The challenge was not just about simplifying complex models, but about making their purpose legible across disciplines: why models matter, why data infrastructure matters, and how they come together to support better outcomes.

In technical spaces, it’s easy to speak in acronyms and methods. But in multistakeholder settings, where time is short and attention spans are precious, that language becomes a barrier. What helped in our case was rooting the conversation in **impact**.

---

### From Problems to Models, Not the Other Way Around

Instead of leading with model architecture or algorithms, we began with the **problems these models help solve**: anticipating the spread of diseases like FMD, LSD, and PPR; identifying optimal vaccination zones; or evaluating the impact of past interventions. These aren’t abstract research exercises—they influence district-level responses, national programme design, and disease control strategy.

Our interactive touchscreen prototype, developed for this event, allowed stakeholders to explore key model applications in an intuitive way. They could simulate an outbreak in a district, compare vaccination coverage over time, or see how population immunity changes with different strategies. This helped move the conversation from “what the model says” to “what decisions the model supports.”

---

### Using Visuals to Tell the Story

We also leaned on design to do some of the heavy lifting. The poster we showcased, designed by [Carlotta](https://carlottacat.com/), distilled the ‘why’, ‘how’, and intended outcomes at a glance, without needing a technical walkthrough.

![Data for Action]({{ '/assets/images/data4action.png' | relative_url }})
*Figure 1: “Data for Action” poster illustrating the initiative’s vision, activities, and pathways to impact.*

---

### Anchoring the Initiative: Three Components

The initiative is structured around three interconnected components, each reinforcing the others.

#### 1. **Data Mechanisms**

This component focuses on strengthening the backbone: the data systems that inform models. We’re improving real-time disease reporting, integrating syndromic and lab-confirmed data, and enabling spatial analysis of risk. These activities align with the **NDLM** and support the establishment of **NADICC** at ICAR-NIVEDI.

> **Models are only as good as the data they are built on.**

Without timely, granular, and high-quality data, even the most sophisticated models risk becoming disconnected from the realities they aim to represent.

#### 2. **Model Development**

Our second component centres on building models tailored to India’s livestock context—compartmental outbreak models, network-based transmission models, and scenario tools. These are not meant to sit in papers. They’re designed for planning, targeting, and real-time response.

We avoided equations in our presentation. Instead, we framed the models as tools to answer practical questions:  
> “Where might the disease go next?”  
> “How can we optimise vaccine allocation under constraints?”  
> “What are the trade-offs of different control strategies?”

We emphasised that the value of these models lies not just in their technical sophistication, but in how they are embedded within real-world decision processes.
> **Data don’t speak for themselves, and neither do models. Insight depends not just on data quality and quantity, but also on context, framing, and purpose.**

#### 3. **Capacity Building**

The final component is about **building local modelling capacity**, not just to use models, but to develop, question, and adapt them. This includes training, partnerships, and co-development with stakeholders.

There is often a gap between those who build models and those who use them or are affected by them. Bridging this gap requires involving decision-makers, field staff, and programme designers from the outset. Building capacity is key to making models trusted, useful, and sustainable.

---

### What I Learned

Framing mattered as much as detail. Starting with purpose and decision-use made the work more relatable. Design, language, and interactivity were essential for making technical work legible and useful in real-world settings.